defaults:
  - cluster: my_local
  - backbone: H512L10
  - element_refs: qh9_lin_refs
  - tasks: qh9_direct
  - _self_

job:
  device_type: ${cluster.device}
  scheduler:
    mode: ${cluster.mode}
    ranks_per_node: ${cluster.ranks_per_node}
    num_nodes: 1
    slurm:
      mem_gb: ${cluster.mem_gb}
      partition: ${cluster.partition}
      timeout_hr: ${cluster.timeout_hr}
      cpus_per_task: ${cluster.cpus_per_task}
      additional_parameters: ${cluster.additional_parameters}
  debug: ${cluster.debug}
  run_dir: ${cluster.run_dir}
  run_name: escaip_mlff_qh9_debug
  logger:
    _target_: fairchem.core.common.logger.WandBSingletonLogger.init_wandb
    _partial_: true
    entity: kaist-korea
    project: qh9_mlff

# cpu_graph: True
max_neighbors: 30
max_neighbors_pad_size: 45
cutoff_radius: 6
epochs: 1
steps: null
max_atoms: 30
backbone:
  max_batch_size: 80
direct_forces_coef: 40
qh9_energy_coef: 10
use_pbc: False

regress_stress: False
direct_forces: True

dataset_list: ["qh9"]

train_dataset:
  _target_: fairchem.core.datasets.qh9_dataset.QH9AtomicDataset
  config:
    processed_dir: /root/25DFT/QHFlow/dataset/QH9Stable_shard/processed
    split: train
    split_filename: processed_QH9Stable_random_12.json
    max_samples: 40
    key_mapping:
      energy: energy
      forces: forces

val_dataset:
  _target_: fairchem.core.datasets.qh9_dataset.QH9AtomicDataset
  config:
    processed_dir: /root/25DFT/QHFlow/dataset/QH9Stable_shard/processed
    split: val
    split_filename: processed_QH9Stable_random_12.json
    max_samples: 40
    key_mapping:
      energy: energy
      forces: forces

train_dataloader:
  _target_: fairchem.core.components.common.dataloader_builder.get_dataloader
  dataset: ${train_dataset}
  batch_sampler_fn:
    _target_: fairchem.core.datasets.samplers.max_atom_distributed_sampler.MaxAtomDistributedBatchSampler
    _partial_: True
    max_atoms: ${max_atoms}
    shuffle: True
    seed: 0
  num_workers: ${cluster.dataloader_workers}
  collate_fn:
    _target_: fairchem.core.units.mlip_unit.mlip_unit.mt_collater_adapter
    tasks: ${tasks}

eval_dataloader:
  _target_: fairchem.core.components.common.dataloader_builder.get_dataloader
  dataset: ${val_dataset}
  batch_sampler_fn:
    _target_: fairchem.core.datasets.samplers.max_atom_distributed_sampler.MaxAtomDistributedBatchSampler
    _partial_: True
    max_atoms: ${max_atoms}
    shuffle: False
    seed: 0
  num_workers: ${cluster.dataloader_workers}
  collate_fn:
    _target_: fairchem.core.units.mlip_unit.mlip_unit.mt_collater_adapter
    tasks: ${tasks}

heads:
  energy:
    module: fairchem.core.models.escaip.EScAIP.EScAIPEnergyHead
  forces:
    module: fairchem.core.models.escaip.EScAIP.EScAIPDirectForceHead

runner:
  _target_: fairchem.core.components.train.train_runner.TrainEvalRunner
  train_dataloader: ${train_dataloader}
  eval_dataloader: ${eval_dataloader}
  train_eval_unit:
    _target_: fairchem.core.units.mlip_unit.mlip_unit.MLIPTrainEvalUnit
    job_config: ${job}
    tasks: ${tasks}
    model:
      _target_: fairchem.core.models.base.HydraModel
      backbone: ${backbone}
      heads: ${heads}
    optimizer_fn:
      _target_: torch.optim.AdamW
      _partial_: true
      lr: 4e-4
      weight_decay: 1e-3
    cosine_lr_scheduler_fn:
      _target_: fairchem.core.units.mlip_unit.mlip_unit._get_consine_lr_scheduler
      _partial_: true
      warmup_factor: 0.2
      warmup_epochs: 2
      lr_min_factor: 0.01
      epochs: ${epochs}
      steps: ${steps}
    print_every: 10
    clip_grad_norm: 100
  max_epochs: ${epochs}
  max_steps: ${steps}
  evaluate_every_n_steps: 5000
  callbacks:
    - _target_: fairchem.core.common.profiler_utils.ProfilerCallback
      job_config: ${job}
    - _target_: fairchem.core.components.train.train_runner.TrainCheckpointCallback
      checkpoint_every_n_steps: 2000
      max_saved_checkpoints: 5
